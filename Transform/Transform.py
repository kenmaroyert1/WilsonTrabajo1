"""ðŸ”„ MÃ“DULO DE TRANSFORMACIÃ“N DE DATOS

Este mÃ³dulo es el TERCER PASO del pipeline ETL. Se encarga de TRANSFORMAR
datos limpios en informaciÃ³n Ãºtil calculando mÃ©tricas derivadas.

ðŸŽ¯ PROPÃ“SITO:
   Convertir datos crudos en mÃ©tricas significativas que revelan patrones,
   tendencias y relaciones en la pandemia de COVID-19.

ðŸ”§ QUÃ‰ HACE:
   1. Promedios mÃ³viles (suaviza fluctuaciones diarias)
   2. Tasas de crecimiento y mortalidad
   3. Agregaciones por fecha/estado/condado
   4. Rankings (top N mÃ¡s afectados)
   5. Matrices de correlaciÃ³n (quÃ© variables se relacionan)
   6. Features temporales (aÃ±o, mes, semana)
   7. NormalizaciÃ³n de datos
   8. DetecciÃ³n y remociÃ³n de outliers

ðŸ’¡ EJEMPLO SIMPLE:
   ```python
   from Transform.Transform import DataTransformer
   import pandas as pd
   
   # Cargar datos limpios
   df = pd.read_csv("Output/IntegratedData_cleaned.csv")
   
   # Crear transformador
   transformer = DataTransformer(df)
   
   # Calcular promedio mÃ³vil de 7 dÃ­as (elimina ruido)
   df_transformed = transformer.calculate_moving_average('daily_cases', window=7)
   
   # Calcular tasa de mortalidad (deaths/cases * 100)
   df_transformed = transformer.calculate_mortality_rate()
   
   # Obtener top 10 estados mÃ¡s afectados
   top_states = transformer.get_top_states('cases', n=10)
   ```

ðŸ“Š FUNCIONES PRINCIPALES:
   - calculate_moving_average(): Suaviza series temporales
   - calculate_mortality_rate(): Calcula letalidad del virus
   - aggregate_by_date(): Suma nacional diaria
   - get_top_states(): Ranking de estados
   - calculate_correlation_matrix(): Relaciones entre variables
"""

from __future__ import annotations

from typing import Optional, List
import pandas as pd
import numpy as np

# ============================================================================
# IMPORTAR CONFIGURACIONES
# ============================================================================

try:
    # Importar constantes desde Config.py
    from Config.Config import (
        MOVING_AVERAGE_WINDOW,  # Ventana para promedio mÃ³vil (7 dÃ­as)
        TOP_N_COUNTIES,         # CuÃ¡ntos condados mostrar (10)
        TOP_N_STATES,           # CuÃ¡ntos estados mostrar (10)
        MOBILITY_COLUMNS,       # Columnas de movilidad
        NUMERIC_COLUMNS         # Columnas numÃ©ricas
    )
except ImportError:
    # Si Config.py no existe, usar valores por defecto
    MOVING_AVERAGE_WINDOW = 7
    TOP_N_COUNTIES = 10
    TOP_N_STATES = 10
    MOBILITY_COLUMNS = ['retail_recreation', 'grocery_pharmacy', 'parks', 
                       'transit', 'workplaces', 'residential']
    NUMERIC_COLUMNS = ['cases', 'deaths', 'daily_cases', 'daily_deaths']


# ============================================================================
# CLASE PRINCIPAL: DataTransformer
# ============================================================================

class DataTransformer:
    """
    ðŸ”„ TRANSFORMADOR DE DATOS - Calcula mÃ©tricas derivadas
    
    Esta clase toma datos limpios y calcula mÃ©tricas Ãºtiles:
    - Promedios mÃ³viles (suaviza fluctuaciones)
    - Tasas de cambio (crecimiento, mortalidad)
    - Agregaciones (sumas por fecha/estado/condado)
    - Rankings (top N mÃ¡s afectados)
    - Correlaciones (quÃ© variables se relacionan)
    """
    
    def __init__(self, df: pd.DataFrame):
        """
        ðŸ—ï¸ CONSTRUCTOR - Inicializa el transformador
        
        Args:
            df: DataFrame con datos limpios (despuÃ©s de Clean.py)
        
        QuÃ© hace:
            - Copia el DataFrame (no modifica el original)
            - Convierte columna 'date' a formato datetime si existe
        
        Ejemplo:
            >>> import pandas as pd
            >>> df = pd.read_csv("Output/IntegratedData_cleaned.csv")
            >>> transformer = DataTransformer(df)
        """
        # Hacer una COPIA del DataFrame (no modificar el original)
        self.df = df.copy()
        
        # Asegurar que la columna 'date' estÃ© en formato correcto
        self._ensure_date_column()
    
    def _ensure_date_column(self):
        """
        ðŸ—“ï¸ ASEGURAR FORMATO DE FECHA - Convierte 'date' a datetime
        
        QuÃ© hace:
            - Busca si existe columna 'date'
            - La convierte a formato datetime de pandas
            - Si ya estÃ¡ en datetime, no hace nada
            - Si tiene errores, pone NaT (Not a Time)
        
        Â¿Por quÃ© es importante?
            - Facilita operaciones con fechas (filtrar, agrupar, ordenar)
            - Permite calcular diferencias entre fechas
            - Necesario para agregaciones temporales
        """
        if 'date' in self.df.columns:
            # Convertir a datetime
            # errors='coerce': Si falla, pone NaT en lugar de error
            self.df['date'] = pd.to_datetime(self.df['date'], errors='coerce')
    
    def calculate_moving_average(self, 
                                 column: str, 
                                 window: int = None,
                                 center: bool = True) -> pd.DataFrame:
        """
        ðŸ“ˆ PROMEDIO MÃ“VIL - Suaviza fluctuaciones diarias
        
        ðŸŽ¯ Â¿QUÃ‰ ES UN PROMEDIO MÃ“VIL?
           Es el promedio de los Ãºltimos N dÃ­as. Elimina picos/valles
           artificiales (ej: menos reportes los fines de semana) y muestra
           la TENDENCIA REAL.
        
        ðŸ“Š EJEMPLO VISUAL:
           Datos diarios:     100, 80, 90, 50, 60, 110, 95
           Promedio mÃ³vil 3:   -,  90, 90, 73, 66, 85,  88
                              (promedio de Ãºltimos 3 valores)
        
        âš ï¸ USO TÃPICO:
           - window=7 (1 semana): Elimina efecto fin de semana
           - window=14 (2 semanas): Suavizado mÃ¡s agresivo
           - window=3 (3 dÃ­as): MÃ¡s sensible a cambios
        
        Args:
            column: Columna a suavizar (ej: 'daily_cases')
            window: Ventana en dÃ­as (default: 7)
            center: Si True, centra la ventana (mÃ¡s preciso)
        Calcula promedio mÃ³vil para una columna.
        
        Args:
            column: Nombre de la columna
            window: Ventana del promedio (dÃ­as)
            center: Si True, centra la ventana
            
        Returns:
            DataFrame con columna adicional de promedio mÃ³vil
        """
        window = window or MOVING_AVERAGE_WINDOW
        
        # Ordenar por fecha
        self.df = self.df.sort_values('date')
        
        # Calcular por grupo si hay county/state
        if 'county' in self.df.columns and 'state' in self.df.columns:
            self.df[f'{column}_ma{window}'] = (
                self.df.groupby(['county', 'state'])[column]
                .transform(lambda x: x.rolling(window=window, center=center).mean())
            )
        else:
            self.df[f'{column}_ma{window}'] = (
                self.df[column].rolling(window=window, center=center).mean()
            )
        
        print(f"âœ… Promedio mÃ³vil calculado: {column}_ma{window}")
        return self.df
    
    def calculate_growth_rate(self, column: str = 'daily_cases') -> pd.DataFrame:
        """
        Calcula tasa de crecimiento diaria.
        
        Args:
            column: Columna para calcular crecimiento
            
        Returns:
            DataFrame con columna de tasa de crecimiento
        """
        self.df = self.df.sort_values('date')
        
        if 'county' in self.df.columns and 'state' in self.df.columns:
            self.df[f'{column}_growth_rate'] = (
                self.df.groupby(['county', 'state'])[column]
                .pct_change() * 100
            )
        else:
            self.df[f'{column}_growth_rate'] = self.df[column].pct_change() * 100
        
        print(f"âœ… Tasa de crecimiento calculada: {column}_growth_rate")
        return self.df
    
    def calculate_mortality_rate(self) -> pd.DataFrame:
        """
        Calcula tasa de mortalidad (deaths / cases * 100).
        
        Returns:
            DataFrame con columna mortality_rate
        """
        self.df['mortality_rate'] = (
            (self.df['deaths'] / self.df['cases']) * 100
        ).replace([np.inf, -np.inf], np.nan)
        
        print("âœ… Tasa de mortalidad calculada: mortality_rate")
        return self.df
    
    def aggregate_by_date(self, agg_dict: Optional[dict] = None) -> pd.DataFrame:
        """
        Agrega datos por fecha (nacional).
        
        Args:
            agg_dict: Diccionario de agregaciÃ³n personalizado
            
        Returns:
            DataFrame agregado por fecha
        """
        if agg_dict is None:
            agg_dict = {
                'cases': 'sum',
                'deaths': 'sum',
                'daily_cases': 'sum',
                'daily_deaths': 'sum'
            }
        
        df_agg = self.df.groupby('date').agg(agg_dict).reset_index()
        print(f"âœ… Datos agregados por fecha: {len(df_agg)} fechas Ãºnicas")
        return df_agg
    
    def aggregate_by_state(self, agg_dict: Optional[dict] = None) -> pd.DataFrame:
        """
        Agrega datos por estado.
        
        Args:
            agg_dict: Diccionario de agregaciÃ³n personalizado
            
        Returns:
            DataFrame agregado por estado
        """
        if 'state' not in self.df.columns:
            raise ValueError("DataFrame no contiene columna 'state'")
        
        if agg_dict is None:
            agg_dict = {
                'cases': 'max',
                'deaths': 'max',
                'daily_cases': 'mean',
                'daily_deaths': 'mean'
            }
        
        df_agg = self.df.groupby('state').agg(agg_dict).reset_index()
        print(f"âœ… Datos agregados por estado: {len(df_agg)} estados")
        return df_agg
    
    def aggregate_by_county(self, agg_dict: Optional[dict] = None) -> pd.DataFrame:
        """
        Agrega datos por condado.
        
        Args:
            agg_dict: Diccionario de agregaciÃ³n personalizado
            
        Returns:
            DataFrame agregado por condado y estado
        """
        if 'county' not in self.df.columns or 'state' not in self.df.columns:
            raise ValueError("DataFrame no contiene columnas 'county' y 'state'")
        
        if agg_dict is None:
            agg_dict = {
                'cases': 'max',
                'deaths': 'max',
                'daily_cases': 'mean',
                'daily_deaths': 'mean'
            }
        
        df_agg = self.df.groupby(['county', 'state']).agg(agg_dict).reset_index()
        print(f"âœ… Datos agregados por condado: {len(df_agg)} condados")
        return df_agg
    
    def get_top_counties(self, metric: str = 'cases', n: int = None) -> pd.DataFrame:
        """
        Obtiene los top N condados por una mÃ©trica.
        
        Args:
            metric: MÃ©trica para ordenar
            n: NÃºmero de condados a retornar
            
        Returns:
            DataFrame con top condados
        """
        n = n or TOP_N_COUNTIES
        
        df_agg = self.aggregate_by_county()
        df_top = df_agg.nlargest(n, metric)
        
        print(f"âœ… Top {n} condados por {metric}")
        return df_top
    
    def get_top_states(self, metric: str = 'cases', n: int = None) -> pd.DataFrame:
        """
        Obtiene los top N estados por una mÃ©trica.
        
        Args:
            metric: MÃ©trica para ordenar
            n: NÃºmero de estados a retornar
            
        Returns:
            DataFrame con top estados
        """
        n = n or TOP_N_STATES
        
        df_agg = self.aggregate_by_state()
        df_top = df_agg.nlargest(n, metric)
        
        print(f"âœ… Top {n} estados por {metric}")
        return df_top
    
    def calculate_correlation_matrix(self, columns: Optional[List[str]] = None) -> pd.DataFrame:
        """
        Calcula matriz de correlaciÃ³n entre columnas numÃ©ricas.
        
        Args:
            columns: Lista de columnas a incluir (None = todas numÃ©ricas)
            
        Returns:
            DataFrame con matriz de correlaciÃ³n
        """
        if columns is None:
            numeric_cols = self.df.select_dtypes(include=[np.number]).columns.tolist()
        else:
            numeric_cols = columns
        
        corr_matrix = self.df[numeric_cols].corr()
        print(f"âœ… Matriz de correlaciÃ³n calculada: {len(numeric_cols)} variables")
        return corr_matrix
    
    def add_time_features(self) -> pd.DataFrame:
        """
        Agrega caracterÃ­sticas temporales derivadas de la fecha.
        
        Returns:
            DataFrame con caracterÃ­sticas temporales adicionales
        """
        if 'date' not in self.df.columns:
            raise ValueError("DataFrame no contiene columna 'date'")
        
        self._ensure_date_column()
        
        # CaracterÃ­sticas temporales
        self.df['year'] = self.df['date'].dt.year
        self.df['month'] = self.df['date'].dt.month
        self.df['week'] = self.df['date'].dt.isocalendar().week
        self.df['day'] = self.df['date'].dt.day
        self.df['day_of_year'] = self.df['date'].dt.dayofyear
        self.df['quarter'] = self.df['date'].dt.quarter
        
        # Ya existe day_of_week en los datos originales, pero podemos verificar
        if 'day_of_week' not in self.df.columns:
            self.df['day_of_week'] = self.df['date'].dt.dayofweek
        
        print("âœ… CaracterÃ­sticas temporales agregadas")
        return self.df
    
    def normalize_column(self, column: str, method: str = 'minmax') -> pd.DataFrame:
        """
        Normaliza una columna numÃ©rica.
        
        Args:
            column: Nombre de la columna
            method: MÃ©todo de normalizaciÃ³n ('minmax' o 'zscore')
            
        Returns:
            DataFrame con columna normalizada
        """
        if column not in self.df.columns:
            raise ValueError(f"Columna '{column}' no encontrada")
        
        if method == 'minmax':
            min_val = self.df[column].min()
            max_val = self.df[column].max()
            self.df[f'{column}_normalized'] = (
                (self.df[column] - min_val) / (max_val - min_val)
            )
        elif method == 'zscore':
            mean_val = self.df[column].mean()
            std_val = self.df[column].std()
            self.df[f'{column}_normalized'] = (
                (self.df[column] - mean_val) / std_val
            )
        else:
            raise ValueError("MÃ©todo debe ser 'minmax' o 'zscore'")
        
        print(f"âœ… Columna normalizada: {column}_normalized (mÃ©todo: {method})")
        return self.df
    
    def filter_outliers(self, column: str, method: str = 'iqr', threshold: float = 1.5) -> pd.DataFrame:
        """
        Filtra outliers de una columna.
        
        Args:
            column: Columna a filtrar
            method: MÃ©todo ('iqr' o 'zscore')
            threshold: Umbral para detecciÃ³n
            
        Returns:
            DataFrame sin outliers
        """
        initial_len = len(self.df)
        
        if method == 'iqr':
            Q1 = self.df[column].quantile(0.25)
            Q3 = self.df[column].quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - threshold * IQR
            upper_bound = Q3 + threshold * IQR
            self.df = self.df[
                (self.df[column] >= lower_bound) & 
                (self.df[column] <= upper_bound)
            ]
        elif method == 'zscore':
            z_scores = np.abs((self.df[column] - self.df[column].mean()) / self.df[column].std())
            self.df = self.df[z_scores < threshold]
        else:
            raise ValueError("MÃ©todo debe ser 'iqr' o 'zscore'")
        
        removed = initial_len - len(self.df)
        print(f"âœ… Outliers removidos: {removed:,} filas ({removed/initial_len*100:.2f}%)")
        return self.df
    
    def get_summary_statistics(self) -> pd.DataFrame:
        """
        Obtiene estadÃ­sticas resumidas del dataset.
        
        Returns:
            DataFrame con estadÃ­sticas descriptivas
        """
        stats = self.df.describe()
        print("âœ… EstadÃ­sticas resumidas generadas")
        return stats


def transform_data(df: pd.DataFrame, operations: List[str] = None) -> pd.DataFrame:
    """
    FunciÃ³n de conveniencia para aplicar mÃºltiples transformaciones.
    
    Args:
        df: DataFrame a transformar
        operations: Lista de operaciones a aplicar
        
    Returns:
        DataFrame transformado
    """
    transformer = DataTransformer(df)
    
    if operations is None:
        operations = ['moving_average', 'mortality_rate', 'time_features']
    
    if 'moving_average' in operations:
        transformer.calculate_moving_average('daily_cases')
        transformer.calculate_moving_average('daily_deaths')
    
    if 'mortality_rate' in operations:
        transformer.calculate_mortality_rate()
    
    if 'growth_rate' in operations:
        transformer.calculate_growth_rate('daily_cases')
    
    if 'time_features' in operations:
        transformer.add_time_features()
    
    return transformer.df


if __name__ == "__main__":
    print("="*60)
    print("MÃ“DULO DE TRANSFORMACIÃ“N DE DATOS")
    print("="*60)
    
    # Ejemplo con datos sintÃ©ticos
    print("\nðŸ“Š Creando datos de ejemplo...")
    dates = pd.date_range('2021-01-01', periods=30)
    df_example = pd.DataFrame({
        'date': dates,
        'county': ['Example'] * 30,
        'state': ['State'] * 30,
        'cases': np.cumsum(np.random.randint(10, 100, 30)),
        'deaths': np.cumsum(np.random.randint(0, 10, 30)),
        'daily_cases': np.random.randint(10, 100, 30),
        'daily_deaths': np.random.randint(0, 10, 30)
    })
    
    # Aplicar transformaciones
    print("\nðŸ”„ Aplicando transformaciones...")
    transformer = DataTransformer(df_example)
    
    # Promedio mÃ³vil
    df_transformed = transformer.calculate_moving_average('daily_cases', window=7)
    
    # Tasa de mortalidad
    df_transformed = transformer.calculate_mortality_rate()
    
    # CaracterÃ­sticas temporales
    df_transformed = transformer.add_time_features()
    
    print("\nðŸ“ˆ Datos transformados (primeras 5 filas):")
    print(df_transformed.head())
    
    print("\n" + "="*60)
